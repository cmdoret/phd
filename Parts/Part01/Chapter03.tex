% Chapter X

\chapter{The importance of genome assembly} % Chapter title

\label{ch:01-03} % For referencing the chapter elsewhere, use \autoref{ch:name} 

%----------------------------------------------------------------------------------------
Most of the genomic techniques presented before require a complete reference genome as downstream analyses will rely on the relative position of different biological elements on the genome sequence to draw biological conclusions. 

A good phylogenetic representation of sequenced genomes is also crucial for comparative analyses. This allows for example to  identify recent \acrshort{HGT} events. Here we describe in more detail the process of genome assembly and its relevance to infection genomics.

\section{From contigs to chromosomes}
% Define terminology, explain advantages of chromosome level assemblies and how to generate them
% Subsections for bionano, linked reads and Hi-C
% Maybe a quick mention of haplotype-resolved assemblies and genome-graphs

Genome assembly consists in reconstructing the linear sequence of the genome from the readings of DNA sequencing technologies. Although the final assembly depends on the quality of these readings, the algorithms used to combine their information are also crucial.

In the early days of genome sequencing, the Sanger method was used to read DNA sequences \cite{sangerDNASequencingChainterminating1977}. Sanger is a low throughput, but highly accurate sequencing method. This technology allowed to unveil the complete genome sequences of viruses  \citep{sangerNucleotideSequenceBacteriophage1982,baerDNASequenceExpression1984}.

Further technological improvements allowed to automate the sequencing process to tackle the sequencing of larger genomes such as eukaryotic orgnanisms. Early genome assembly peojects were performed using laborious and costly experimental methods, such as \acrfull{BAC}, which involved cloning long overlapping pieces of DNA of the genome into bacteria. These pieces were then experimentally amplified and sequenced in parallel. Ovelapping ends from each of those sequences had to be aligned to recover the entire chromosome sequence. The first genome sequencing projects were sizable undertakings requiring the collaboration of many research groups throughout the world \citep{collinsNewFiveyearPlan1993,adamsGenomeSequenceDrosophila2000}, but technological advancements progressively reduced the cost and time investment. A decisive change was the development of shotgun sequencing \cite{venterSequenceHumanGenome2001}, which involves randomly sequencing regions to cover the entire genome.

With the advent of \acrfull{NGS}, shotgun sequencing became the standard for whole genome sequencing. \acrshort{NGS} had much higher throughput, allowing to sequence megabases of DNA very quickly. However, it could only read short sequences at a time, referred to as \Gls{read}s. With a large number of short reads, the problem of genome assembly became impossible to solve by hand. This brought a whole new field of bioinformatics to life: The development of genome assembly algorithms \citep{simpsonABySSParallelAssembler2009,zerbinoVelvetAlgorithmsNovo2008}.

The goal of these algorithms is to generate highly contiguous genome assemblies from a large number of short reads. Most algorithms generate a \textit{de Bruijn} graphs, where individual sequences are edges and overlaps are nodes. To assemble a genome, one needs to find the Eulerian path, which passes through every edge exactly once. However this is often not possible because of repeated sequences in the genome, sequencing errors and haplotypes \cite{simpsonTheoryPracticeGenome2015}. Whenever a repeated sequence is longer than the read itself, the graph can not be solved and heuristics have to be used. The resulting assemblies usually have a relatively high number of "solved" pieces called \Gls{contig}s.

Third generation sequencing partially alleviates this issue by generating long albeit less accurate reads. Read lengths up to hundreds of thousands of basepairs can be generated, which allows to span most repeated regions. Recently, these technologies were used to generate telomere-to-telomere assemblies of several human chromosomes \cite{migaTelomeretotelomereAssemblyComplete2020}. These techniques still suffer from their lower base calling accuracy and are often combined with short accurate reads to correct these errors, a process known as \Gls{polishing}. They can be used to generate assemblies \textit{de-novo}, or to combine contigs of existing NGS assemblies into \Gls{scaffold}s.

More recently the emergence of specialized technologies aimed at scaffolding have allowed to generate even more continuous and correct genomes at reduced costs. One example is the recent rebirth of optical mapping to introduce fluorescent probes into chromosomes at specific sites \cite{lamGenomeMappingNanochannel2012}. The order of these probes and their relative distance form barcodes which can then be used to scaffold genome assemblies, reorder and merge contigs. This is often combined with Hi-C to generate highly continuous assemblies even in the presence of repeated sequences.

Most recent genome assemblies combine a number of these different technologies to bring the number of scaffolds as close as possible to the real number of chromosomes.

\section{Phylogenetic representation}
% HGT detection requires a reference group

A common way to analyze the genome of new microorganisms is to compare it to other species. To achieve this, one needs to have other closely related genomes available. A common case where dense species genome representation is required is when attempting to detect \acrshort{HGT}.

\acrshort{HGT} detection methods often rely on discordance between gene trees and species trees. A horizontally transferred gene between two distant species would show strong sequence similarity \cite{ravenhallInferringHorizontalGene2015}. For this reason, detection of recent events requires genomes of closely related organisms as a comparison point.

Another frequent analysis when comparing a group of strains or species of microorganisms is to define the common set of genes they share, known as pangenome. This also allows the identification of genes specific to a particular genome, known as accessory genome. Such sets can be helpful to determine metabolic reactions associated with species or niches, however they heavily depend on the proportion of available species in the group.

Lately, several large consortia \citep{genome10kcommunityofscientistsGenome10KProposal2009,poelchauI5kWorkspaceNAL2015,DarwinTreeLife} undertook the daunting task of sequencing thousands of organisms throughout the tree of life. For the aforementioned reasons, these large collaborations are likely to greatly improve the power of comparative genomic analyses results in the future.

\section{The transition to genome graphs}

Until recently, all reference genomes were exclusively stored as linear (or circular) sequences of DNA. This linear sequence is often obtained from a mix of multiple individuals, or alleles within an individual. It is effectively a semi-arbitrary combination of multiple haplotypes collapsed into an artificial consensus sequence. A more accurate alternative is to produce a reference sequence graph instead \cite{churchExtendingReferenceAssembly2015}. Given a collection of haplotypes, individuals, or strains of a species, one can generate a graph where identical regions are collapsed, while sample-specific variants form bubbles retaining the genetic variability. As this approach is relatively recent, few algorithms have been developed to operate on sequence graphs, making their applications very limited.

The shift to genome graphs is promising for the analysis of bacterial samples, where alignment can be performed on multiple strain references at the same time. Doing this with a collection of linear genome incurs mapping bias due to ambiguous alignments between redundant regions between references \cite{liDesignConstructionReference2020}. Similarly, genome graphs also allow systematic alignment to different alleles in polyploid organisms, solving the issue of allele-specific mapping bias in linear references \cite{vandegeijnWASPAllelespecificSoftware2015}. 